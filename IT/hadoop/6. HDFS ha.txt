HDFS
    分布式系统
	* NameNode
	  元数据
	  文件名称/路径/所属者/所属组/权限/副本数
	  
	* DataNode
	   128M
	   Block方式存储
	   本地磁盘
	       dfs.datanode.data.dir=path
		   
	* Client
	   -> NameNode ->
	   
	   
HDFS HA 2.x版本发布的
======================================================

    * NameNode Active 
	* NameNode Standby(对NameNode Active进行热备)
	
	
	SPOF(Single Point Of Failure)

	客户端通过Proxy(多台机器?)对NameNode进行请求
	使用ZooKeep做自动故障转移
	
	如何保证两个NameNode的元数据一致?
	NameNode Active 向共享编辑日志(JournalNode)中写
	   如果出现不一致, 通过ZooKeeper裁判
	NameNode Standby 从共享编辑日志(JournalNode)中读取
	
	其他DataNode同时向两种NameNode发送心跳报告
	
    四大要点

	1. Shared Edits
	2. NameNode
	    Active Standby
	3. Client proxy
	4. fence
	    同一时刻只有一个NameNode提供服务
		
		
		
		
Hadoop HA配置
=========================================


启动
    1. 各个JournalNode节点上启动JournalNode
	   hadoop-daemon.sh start journalnode
	2. 在NN1上进行格式化并启动
	   hdfs namenode -format
	   hadoop-daemon.sh start namenode
	3. NN2上同步NN1的元数据信息
	   hdfs namenode -bootstrapStandby
	4. 启动NN2
	   hadoop-daemon.sh start namenode
	5. NN1上启动所有DataNode  
	   hadoop-daemon.sh start datanode
	6. NN1切换为Active
	   hdfs haadmin -transitionToActive NN1切换为Active
	
自动故障转移配置(ZooKeeper)
==========================================
  启动后都是Standby
     需要选举一个为Active
  监控
     ZKFC(ZooKeeper Failover Controller)
	 
	 
配置
   hdfs-site.xml
     dfs.ha.automatic-failover.enabled=true

   core-site.xml
     ha.zookeeper.quorum=host1:port1,host2:port2...

启动过程
   1. 启动ZooKeeper集群
   2. 初始化HA在ZooKeeper中的状态
      hdfs zkfc -formatZK
   3. 启动HDFS
      start-dfs.sh
   4. 	  
	 
   host1           host2            host3
   NameNode        NameNode
   
   ZKFC            ZKFC
   
   JournalNode     JournalNode      JournalNode