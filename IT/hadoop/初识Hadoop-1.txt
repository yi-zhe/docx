GFS        ->    HDFS
    存储海量数据
    分布式的
    思想
       分而治之: 大数据集分为小的数据集
       每个数据集进行逻辑业务处理(Map)
       合并统计数据结果(Reduce)

    数据以block的方式进行存储


MapReduce  ->    MapReduce
    对海量数据的处理
    分布式
    安全性
        副本数据, 多个副本


BigTable   ->    HBase


YARN
    分布式资源管理框架
    管理整个集群的资源(内存、CPU、磁盘、网络等)
    分配调度集群资源
    

NameNode
========================

    * 内存
    * 本地磁盘
         fsimage  镜像文件
         edits    编辑日志

    1. 存储文件的元数据(文件名、目录结构、文件属性、时间、副本数、权限以及文件的块列表和块所在DataNode)


DataNode
========================

    1. 在本地文件系统存储文件块数据以及数据的校验和


MapReduce
========================
    1. Map阶段并行处理输入数据
    2. Reduce阶段对Map结果进行汇总

    3. Shuffle连接Map和Reduce
    4. ReduceTask从每个MapTask上读取一份数据

    5. 仅适合离线批处理
    6. 适合简单的批处理任务

    7. 启动开销大, 过多使用磁盘


启动方式
========================
    各个服务组件逐一启动
    1. hdfs
       hadoop-daemon.sh start|stop namenode|datanode|secondarynamenode

    2. yarn
       yarn-daemon.sh start|stop resourcemanager|nodemanager

    各个模块分开启动
       hdfs
       start-dfs.sh | stop-dfs.sh

       yarn
       start-yarn.sh | stop-yarn.sh


Hadoop 2.x
========================

    * common
    * HDFS
        存储数据
        NameNode
            存储文件系统元数据 命名空间
        
        DataNode 
            存储数据

        SecondaryNamenode
            辅助NameNode工作 周期性合并两个文件

     * YARN
        Hadoop 操作系统
        Data   操作系统
        Container
        ResourceManager
               整个集群资源的管理与调度
        NodeManager
               管理每个节点的资源与调度




     * MapReduce
        分而治之

        * map 分

        * reduce 合

        input -> map -> shuffle -> reduce -> output

历史服务器 (http://namenodeip:19888)
===========================

    启动 mr-jobhistory-daemon.sh start historyserver



日志聚集功能(将应用运行完成后, 将日志信息上传到HDFS文件系统上)
http://namenodeip:
===========================

    启动日志聚集: 在yarn-site.xml中增加
    <property>
          <name>yarn.log-aggregation-enable</name>
          <value>true</value>
    </property>


配置文件
===========================
    * 默认配置文件
      core-default.xml
      hdfs-default.xml
      yarn-default.xml
      mapred-default.xml

    * 自定义配置文件
      core-site.xml
      hdfs-site.xml
      yarn-site.xml
      mapred-site.xml

一段代码获得HDFS系统对象
===========================

    public static void main(String[] args) {
        Configuration conf = new Configuration();
        FileSystem fileSystem = new FileSystem(conf);

        System.out.println(fileSystem);
    }















