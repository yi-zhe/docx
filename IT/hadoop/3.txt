使用HDFS API访问HDFS文件系统
===================================
    1. Configuration
        加载配置文件
        从类路径中加载
    2. FileSystem
        DistributedFileSystem
    3. Path
        文件或路径的名称的抽象
        绝对路径以/开头
        相对路径以家目录为参考点

    4. 

block
==================================
    128M
    磁盘寻道时间 10ms
    10ms / 1% = 1000ms
    磁盘读取速度100M/s
    大概的块大小 1000ms * 100M/s = 100M

多目录结构
=================================
    1. NameNode配置多目录
       是副本的概念

    2. DataNode
       不是副本的概念

在eclipse中安装hadoop插件 方便访问hdfs
================================
    1. 下载hadoop2x-eclipse-plugin.zip
    2. 解压hadoop2x-eclipse-plugin.zip/release/*.jar 到 $eclipse_home/plugins/
    3. 重启eclipse
    4. 验证是否安装成功

剖析文件写入过程
================================
    1. 客户端调用分布式文件系统的create方法
    2. 分布式文件系统调用NameNode的create方法
    3. 客户端拿到FSDataOutputStream并调用write方法
    4. 将数据包写到第一个数据队列中, 然后写入数据节点, 然后通过pipeline向其他数据节点写入
    5. 回复写入成功
    6. 客户端关闭输出流
    7. 通知NameNode写入完成

副本节点的选择
===============================
    默认:  1. 第一个副本在client所处的节点, 如果客户端在集群外, 则随机选一个
           2. 第二个副本放在与第一个不同且随机另外选择的机架中节点上
           3. 第三个副本与第二个副本在同一个机架上, 且随机选择另一个节点
    
    hadoop2.7.2
           1. 第一个副本在client所处的节点, 如果客户端在集群外, 则随机选一个
           2. 第二个副本放在与第一个相同机架的另一个节点上 
           3. 第三个副本在不同的机架上

自定义机架感知
===============================
    1. 创建DNSToSwitchMapping接口的实现类
    2. core-site.xml中配置topology.node.switch.mapping.impl
    3. 分发core-site.xml
    3. 编译成jar并分发到集群中的各个机器的Hadoop classpath下

增加一个数据节点
===============================
    1. 克隆一个节点
    2. 启动新节点
    3. 修改ip主机名
    4. 修改s100的/etc/hosts 然后分发
    5. 在s200上测试ssh s205
    6. 修改分发脚本/修改s200上的slaves文件并分发
    7. 







 










    
